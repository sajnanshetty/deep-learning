{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA4 - Session 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import pdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        #withot batch norm parameters = 6,379,786 accuracy 97.92%\n",
        "        #with batch norm parameters =  6,383,818 accuracy 98.76%\n",
        "        #with batch norm and dropout parameters =  6,383,818 accuracy 98.61% (dropout after relu with dropout value .2)\n",
        "        #with batch norm and dropout parameters =  6,383,818 accuracy 98.74% (dropout after relu with dropout value .1)\n",
        "        #with batch norm and dropout parameters =  6,383,818 accuracy 99.03% (dropout after relu with dropout value .05)\n",
        "        #with batch norm and dropout parameters =  6,383,818 accuracy 98.92% (dropout before relu with dropout value .05)\n",
        "        #with batch norm and dropout parameters =  6,383,818 accuracy 98.95% (dropout after conv with dropout value .05)\n",
        "        # self.conv1 = nn.Conv2d(1, 32, 3, padding=1) #input -? OUtput? RF\n",
        "        # self.batch1 = nn.BatchNorm2d(32)\n",
        "        # self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        # self.batch2 = nn.BatchNorm2d(64)\n",
        "        # self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        # self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        # self.batch3 = nn.BatchNorm2d(128)\n",
        "        # self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        # self.batch4 = nn.BatchNorm2d(256)\n",
        "        # self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        # self.conv5 = nn.Conv2d(256, 512, 3)\n",
        "        # self.batch5 = nn.BatchNorm2d(512)\n",
        "        # self.conv6 = nn.Conv2d(512, 1024, 3)\n",
        "        # self.batch6 = nn.BatchNorm2d(1024)\n",
        "        # self.conv7 = nn.Conv2d(1024, 10, 3)\n",
        "        \"\"\"\n",
        "        Summary from above trail for better accuracy:\n",
        "        Using Dropuout 0.05 gives better result(compaired to .1 and .2)\n",
        "        Applying BatchNorm after Conv function.\n",
        "        Dropuout after Relu activation function.\n",
        "        \"\"\"\n",
        "        p = 0.05\n",
        "        self.dropuout= nn.Dropout2d(p)\n",
        "        #conv1 parameters = (3 x 3 x 1 + 1(bias)) x 16 = 160\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1) #input -1, Output=16,  RF=3\n",
        "        self.batch1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 16, 3, padding=1) #input -16, Output=16, RF=5\n",
        "        self.batch2 = nn.BatchNorm2d(16)\n",
        "        self.conv3 = nn.Conv2d(16, 16, 3, padding=1) #input -16, Output=16, RF=7\n",
        "        self.batch3 = nn.BatchNorm2d(16)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)               #RF =14\n",
        "        self.conv4 = nn.Conv2d(16, 16, 3, padding=1)    # input- 16, Output = 16, RF=16\n",
        "        self.batch4 = nn.BatchNorm2d(16)\n",
        "        self.conv5 = nn.Conv2d(16, 16, 3, padding=1)   # input- 16, Output = 16, RF=18\n",
        "        self.batch5 = nn.BatchNorm2d(16)\n",
        "        self.conv6 = nn.Conv2d(16, 16, 3, padding=1) # input- 16, Output = 16, RF=20\n",
        "        self.batch6 = nn.BatchNorm2d(16)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)             # RF=40\n",
        "        self.conv7 = nn.Conv2d(16, 16, 3)            # input- 16, Output = 16, RF=42\n",
        "        self.batch7 = nn.BatchNorm2d(16)\n",
        "        self.conv8 = nn.Conv2d(16, 16, 3)           # input- 16, Output = 16, RF=44\n",
        "        self.batch8 = nn.BatchNorm2d(16)\n",
        "        self.conv9 = nn.Conv2d(16, 10, 3)             # input- 16, Output = 10, RF=46\n",
        "\n",
        "    def forward(self, x):\n",
        "        #pdb.set_trace()\n",
        "        x = self.pool1(self.dropuout(F.relu(self.batch3(self.conv3(\n",
        "            self.dropuout(F.relu(self.batch2(self.conv2(\n",
        "                self.dropuout(F.relu(self.batch1(self.conv1(x)))))))))))))\n",
        "        x = self.pool2(self.dropuout(F.relu(self.batch6(self.conv6(\n",
        "            self.dropuout(F.relu(self.batch5(\n",
        "                self.conv5(self.dropuout(F.relu(self.batch4(self.conv4(x)))))))))))))\n",
        "        x = self.dropuout(F.relu(self.batch8(self.conv8(self.dropuout(F.relu(self.batch7(self.conv7(x))))))))\n",
        "        x = self.conv9(x)\n",
        "        x = x.view(-1, 10)\n",
        "        # x = self.pool1(self.dropuout(F.relu(self.batch2(self.conv2(self.dropuout(F.relu(self.batch1(self.conv1(x)))))))))\n",
        "        # x = self.pool2(self.dropuout(F.relu(self.batch4(self.conv4(self.dropuout(F.relu(self.batch3(self.conv3(x)))))))))\n",
        "        # x = self.dropuout(F.relu(self.batch6(self.conv6(self.dropuout(F.relu(self.batch5(self.conv5(x))))))))\n",
        "        # x = self.conv7(x)\n",
        "        # x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xdydjYTZFyi3",
        "outputId": "46c7a201-4311-4eed-bfd5-58c58a50e38a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 28, 28]             160\n",
            "       BatchNorm2d-2           [-1, 16, 28, 28]              32\n",
            "         Dropout2d-3           [-1, 16, 28, 28]               0\n",
            "            Conv2d-4           [-1, 16, 28, 28]           2,320\n",
            "       BatchNorm2d-5           [-1, 16, 28, 28]              32\n",
            "         Dropout2d-6           [-1, 16, 28, 28]               0\n",
            "            Conv2d-7           [-1, 16, 28, 28]           2,320\n",
            "       BatchNorm2d-8           [-1, 16, 28, 28]              32\n",
            "         Dropout2d-9           [-1, 16, 28, 28]               0\n",
            "        MaxPool2d-10           [-1, 16, 14, 14]               0\n",
            "           Conv2d-11           [-1, 16, 14, 14]           2,320\n",
            "      BatchNorm2d-12           [-1, 16, 14, 14]              32\n",
            "        Dropout2d-13           [-1, 16, 14, 14]               0\n",
            "           Conv2d-14           [-1, 16, 14, 14]           2,320\n",
            "      BatchNorm2d-15           [-1, 16, 14, 14]              32\n",
            "        Dropout2d-16           [-1, 16, 14, 14]               0\n",
            "           Conv2d-17           [-1, 16, 14, 14]           2,320\n",
            "      BatchNorm2d-18           [-1, 16, 14, 14]              32\n",
            "        Dropout2d-19           [-1, 16, 14, 14]               0\n",
            "        MaxPool2d-20             [-1, 16, 7, 7]               0\n",
            "           Conv2d-21             [-1, 16, 5, 5]           2,320\n",
            "      BatchNorm2d-22             [-1, 16, 5, 5]              32\n",
            "        Dropout2d-23             [-1, 16, 5, 5]               0\n",
            "           Conv2d-24             [-1, 16, 3, 3]           2,320\n",
            "      BatchNorm2d-25             [-1, 16, 3, 3]              32\n",
            "        Dropout2d-26             [-1, 16, 3, 3]               0\n",
            "           Conv2d-27             [-1, 10, 1, 1]           1,450\n",
            "================================================================\n",
            "Total params: 18,106\n",
            "Trainable params: 18,106\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.12\n",
            "Params size (MB): 0.07\n",
            "Estimated Total Size (MB): 1.19\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "torch.manual_seed(1)\n",
        "batch_size = 64\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWbLWO6FuHb",
        "colab_type": "code",
        "outputId": "af099215-a713-4b4c-95da-5b0a064bc275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "#for epoch in range(1, 2):\n",
        "for epoch in range(1, 20):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/938 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "loss=0.07818733155727386 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 58.56it/s]\n",
            "  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0428, Accuracy: 9860/10000 (98.60%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.03627479076385498 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 58.50it/s]\n",
            "  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0330, Accuracy: 9895/10000 (98.95%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.009423583745956421 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 57.58it/s]\n",
            "  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0273, Accuracy: 9918/10000 (99.18%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.012739792466163635 batch_id=937: 100%|██████████| 938/938 [00:15<00:00, 58.65it/s]\n",
            "  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0236, Accuracy: 9928/10000 (99.28%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.0018846690654754639 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 57.76it/s]\n",
            "  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0262, Accuracy: 9926/10000 (99.26%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.10518613457679749 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 58.31it/s]\n",
            "  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0234, Accuracy: 9928/10000 (99.28%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.02803926169872284 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 57.25it/s]\n",
            "  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0226, Accuracy: 9922/10000 (99.22%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.007726207375526428 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 56.78it/s]\n",
            "  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0194, Accuracy: 9942/10000 (99.42%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.04060518741607666 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 55.84it/s]\n",
            "  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0192, Accuracy: 9940/10000 (99.40%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.020323365926742554 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 56.03it/s]\n",
            "  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0211, Accuracy: 9929/10000 (99.29%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.15697252750396729 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 57.58it/s]\n",
            "  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0203, Accuracy: 9930/10000 (99.30%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.0302266925573349 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 56.68it/s]\n",
            "  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0207, Accuracy: 9939/10000 (99.39%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.08217889070510864 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 58.15it/s]\n",
            "  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0195, Accuracy: 9941/10000 (99.41%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.002729475498199463 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 58.14it/s]\n",
            "  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0198, Accuracy: 9939/10000 (99.39%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.012728244066238403 batch_id=937: 100%|██████████| 938/938 [00:15<00:00, 59.10it/s]\n",
            "  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0204, Accuracy: 9938/10000 (99.38%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.004750475287437439 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 57.22it/s]\n",
            "  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0181, Accuracy: 9945/10000 (99.45%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.0001894533634185791 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 58.24it/s]\n",
            "  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0182, Accuracy: 9941/10000 (99.41%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.014946460723876953 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 58.55it/s]\n",
            "  0%|          | 0/938 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0198, Accuracy: 9942/10000 (99.42%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.0061161816120147705 batch_id=937: 100%|██████████| 938/938 [00:16<00:00, 57.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0167, Accuracy: 9952/10000 (99.52%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So5uk4EkHW6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}